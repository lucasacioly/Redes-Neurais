{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, mean_squared_error, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando conjuntos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset_tratado/train_df.csv\")\n",
    "df_val = pd.read_csv(\"dataset_tratado/validation_df.csv\")\n",
    "df_test = pd.read_csv(\"dataset_tratado/test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('satisfied', axis=1)\n",
    "y_train = df_train['satisfied'].astype(int)\n",
    "\n",
    "X_val = df_val.drop('satisfied', axis=1)\n",
    "y_val = df_val['satisfied'].astype(int)\n",
    "\n",
    "X_test = df_test.drop('satisfied', axis=1)\n",
    "y_test = df_test['satisfied'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "def extract_final_losses(history):\n",
    "    \"\"\"Função para extrair o melhor loss de treino e validação.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    Dicionário contendo o melhor loss de treino e de validação baseado \n",
    "    no menor loss de validação.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    idx_min_val_loss = np.argmin(val_loss)\n",
    "    return {'train_loss': train_loss[idx_min_val_loss], 'val_loss': val_loss[idx_min_val_loss]}\n",
    "\n",
    "def plot_training_error_curves(history):\n",
    "    \"\"\"Função para plotar as curvas de erro do treinamento da rede neural.\n",
    "    \n",
    "    Argumento(s):\n",
    "    history -- Objeto retornado pela função fit do keras.\n",
    "    \n",
    "    Retorno:\n",
    "    A função gera o gráfico do treino da rede e retorna None.\n",
    "    \"\"\"\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_loss, label='Train')\n",
    "    ax.plot(val_loss, label='Validation')\n",
    "    ax.set(title='Training and Validation Error Curves', xlabel='Epochs', ylabel='Loss (MSE)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_matrix(cm: np.ndarray):\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_percent, annot=True, cmap='Blues', fmt='.1%', cbar=False)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y_test, y_pred_class, y_pred_scores=None):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    \n",
    "    # Calculate precision, recall, and f1-score\n",
    "    recall = recall_score(y_test, y_pred_class)\n",
    "    precision = precision_score(y_test, y_pred_class)\n",
    "    f1 = f1_score(y_test, y_pred_class)\n",
    "    performance_metrics = (accuracy, recall, precision, f1)\n",
    "    if y_pred_scores is not None:\n",
    "        skplt.metrics.plot_ks_statistic(y_test, y_pred_scores)\n",
    "        plt.show()\n",
    "        y_pred_scores = y_pred_scores[:, 1]\n",
    "        auroc = roc_auc_score(y_test, y_pred_scores)\n",
    "        aupr = average_precision_score(y_test, y_pred_scores)\n",
    "        performance_metrics = performance_metrics + (auroc, aupr)\n",
    "    return performance_metrics\n",
    "\n",
    "def print_metrics_summary(accuracy, recall, precision, f1, auroc=None, aupr=None):\n",
    "    print()\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Accuracy:\", value=accuracy))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Recall:\", value=recall))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"Precision:\", value=precision))\n",
    "    print(\"{metric:<18}{value:.4f}\".format(metric=\"F1:\", value=f1))\n",
    "    if auroc is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUROC:\", value=auroc))\n",
    "    if aupr is not None:\n",
    "        print(\"{metric:<18}{value:.4f}\".format(metric=\"AUPR:\", value=aupr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições no Conjunto de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_class = rf.predict(X_val)\n",
    "rf_pred_scores = rf.predict_proba(X_val)\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_val, rf_pred_class, rf_pred_scores)\n",
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=50, cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = random_search.best_estimator_\n",
    "\n",
    "# Avaliando o modelo com validação cruzada\n",
    "cross_val_scores = cross_val_score(rf_best, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation scores:\", cross_val_scores)\n",
    "print(\"Mean cross-validation score:\", cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reavaliação no conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = rf_best.predict(X_val)\n",
    "y_val_pred_scores = rf_best.predict_proba(X_val)\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_val, y_val_pred, y_val_pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusão no conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "plot_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predições no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf_best.predict(X_test)\n",
    "y_test_pred_scores = rf_best.predict_proba(X_test)\n",
    "accuracy, recall, precision, f1, auroc, aupr = compute_performance_metrics(y_test, y_test_pred, y_test_pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_summary(accuracy, recall, precision, f1, auroc, aupr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plot_matrix(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
